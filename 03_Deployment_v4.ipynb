{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2e6095-2729-49c3-950a-e4c046f1a522",
   "metadata": {},
   "source": [
    "# Deploiement de la pipeline de recommandation personalisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310fc7e-b99a-46e1-acab-f143407264a6",
   "metadata": {},
   "source": [
    "Ce notebook a pour but de créer un ensemble triton pour déployer le système de recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93abcf37-7130-4d3c-a01c-972505d8d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install \"feast<0.31\" faiss-gpu\n",
    "#!pip install seedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4c5466-dbd4-4f33-9f36-9ba9a6761545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py:29: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils as _distutils\n",
      "2024-09-16 13:42:48.964376: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 13:42:49.011759: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/usr/local/lib/python3.10/dist-packages/nvtabular/loader/__init__.py:19: DeprecationWarning: The `nvtabular.loader` module has moved to a new repository, at https://github.com/NVIDIA-Merlin/dataloader .  Support for importing from `nvtabular.loader` is deprecated, and will be removed in a future version. Please update your imports to refer to `merlinloader`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feast\n",
    "import seedir as sd\n",
    "from nvtabular import ColumnSchema, Schema\n",
    "\n",
    "from merlin.systems.dag.ensemble import Ensemble\n",
    "from merlin.systems.dag.ops.softmax_sampling import SoftmaxSampling\n",
    "from merlin.systems.dag.ops.tensorflow import PredictTensorflow\n",
    "from merlin.systems.dag.ops.unroll_features import UnrollFeatures\n",
    "from merlin.systems.triton.utils import send_triton_request\n",
    "from merlin.systems.dag.ops.workflow import TransformWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127cb8e-ce15-4106-9b2b-ebd87c1ec804",
   "metadata": {},
   "source": [
    "## Enregistrement des features dans le feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb176315-4549-466a-a7cc-2f165fdbdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/root/Data/Row/\")\n",
    "DATA_FOLDER = os.environ.get(\"DATA_FOLDER\", \"/root/Data/\")\n",
    "MODELS_FOLDER = os.environ.get(\"MODELS\", \"/root/Models/\")\n",
    "PROCESSED_FOLDER = os.environ.get(\"PROCESSED_FOLDER\", \"/root/Data/Processed/\")\n",
    "feature_repo_path = os.environ.get(\"FEAST_PATH\", \"/root/Data/feast_repo/feature_repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82102af-9afa-48c5-8159-9d71366f9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_repo/\n",
      "├─__init__.py\n",
      "├─__pycache__/\n",
      "│ ├─__init__.cpython-310.pyc\n",
      "│ ├─example_repo.cpython-310.pyc\n",
      "│ └─test_workflow.cpython-310.pyc\n",
      "├─cufile.log\n",
      "├─data/\n",
      "│ ├─item_features.parquet\n",
      "│ ├─online_store.db\n",
      "│ ├─registry.db\n",
      "│ └─user_features.parquet\n",
      "├─feature_store.yaml\n",
      "├─item_features.py\n",
      "├─test_workflow.py\n",
      "└─user_features.py\n"
     ]
    }
   ],
   "source": [
    "import seedir as sd\n",
    "\n",
    "feature_repo_path = os.path.join(feature_repo_path)\n",
    "sd.seedir(\n",
    "    feature_repo_path,\n",
    "    style=\"lines\",\n",
    "    itemlimit=10,\n",
    "    depthlimit=3,\n",
    "    #exclude_folders=\".ipynb_checkpoints\",\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3c3bc-8f6f-45c2-bae0-932f0c8a5f12",
   "metadata": {},
   "source": [
    "Enregistrementdes données dans le feature store.\n",
    "Le Feast feature registry est le catalogue centrale des définitions des features et des metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7271c5-2018-43df-afab-0db52b9da56e",
   "metadata": {},
   "source": [
    "Chargement des features depuis l'offline store à l'online store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe933311-504f-4a3f-b8f2-faf645b8ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Data/feast_repo/feature_repo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created entity \u001b[1m\u001b[32mitem_id\u001b[0m\n",
      "Created entity \u001b[1m\u001b[32muser_id\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32mitem_features\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32muser_features\u001b[0m\n",
      "\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_repo_item_features\u001b[0m\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_repo_user_features\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd $feature_repo_path\n",
    "!find . -name \".ipynb_checkpoints\" -exec rm -r {} +\n",
    "!feast apply\n",
    "\n",
    "#!find . -name \".ipynb_checkpoints\" -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80e55db-4e2c-4879-85a9-8504571df71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views from \u001b[1m\u001b[32m1995-01-01 01:01:01+00:00\u001b[0m to \u001b[1m\u001b[32m2025-01-01 01:01:01+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mitem_features\u001b[0m:\n",
      "100%|███████████████████████████████████████████████████████| 23417/23417 [00:13<00:00, 1762.09it/s]\n",
      "\u001b[1m\u001b[32muser_features\u001b[0m:\n",
      "100%|█████████████████████████████████████████████████████| 442707/442707 [04:56<00:00, 1493.12it/s]\n"
     ]
    }
   ],
   "source": [
    "!feast materialize 1995-01-01T01:01:01 2025-01-01T01:01:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97fd8d36-92bb-4761-8153-8bfc0dde77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_repo/\n",
      "├─__init__.py\n",
      "├─__pycache__/\n",
      "│ ├─__init__.cpython-310.pyc\n",
      "│ ├─example_repo.cpython-310.pyc\n",
      "│ └─test_workflow.cpython-310.pyc\n",
      "├─data/\n",
      "│ ├─item_features.parquet\n",
      "│ ├─online_store.db\n",
      "│ ├─registry.db\n",
      "│ └─user_features.parquet\n",
      "├─feature_store.yaml\n",
      "├─item_features.py\n",
      "├─test_workflow.py\n",
      "└─user_features.py\n"
     ]
    }
   ],
   "source": [
    "# set up the base dir to for feature store\n",
    "sd.seedir(os.path.join(feature_repo_path), style='lines', itemlimit=10, depthlimit=5, sort=True) #exclude_folders=['.ipynb_checkpoints', '__pycache__']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f1268-ad3c-4722-b0f9-10bf8cfe138e",
   "metadata": {},
   "source": [
    "Création du client du feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d1ad84-a9d3-43fc-b806-a89c066ac621",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = feast.FeatureStore(feature_repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535287e-573c-42ef-ac28-ce7b3b2f5543",
   "metadata": {},
   "source": [
    "Definition des chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "12a6bf12-51e5-4497-b165-b6214fef43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(DATA_FOLDER, 'faiss_index')):\n",
    "    os.makedirs(os.path.join(DATA_FOLDER, 'faiss_index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6c2d47b-00d6-420a-92ce-2568e37c93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index_path = os.path.join(DATA_FOLDER, 'faiss_index', \"index.faiss\")\n",
    "retrieval_model_path = os.path.join(MODELS_FOLDER, \"query_tower/\")\n",
    "ranking_model_path = os.path.join(MODELS_FOLDER, \"dlrm/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa42782-3490-4141-8485-5aa90073972a",
   "metadata": {},
   "source": [
    "Create de l'index Faiss à partir des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4d4d1316-605c-4b99-92c6-99da51a9ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.systems.dag.ops.faiss import QueryFaiss, setup_faiss \n",
    "\n",
    "item_embeddings = pd.read_parquet(os.path.join(DATA_FOLDER, \"Processed/item_embeddings.parquet\"))\n",
    "setup_faiss(item_embeddings, faiss_index_path, embedding_column=\"output_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb78718-aa27-4a05-9450-19e8ae51d9cf",
   "metadata": {},
   "source": [
    "## Definition de la pipeline de recommandation complète avec Nvtabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b95c82db-c513-4122-835f-42cc5a7f7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class EnhancedTimedQueryFeast(QueryFeast):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.log_file = open('queryfeast_logs.txt', 'w')\n",
    "\n",
    "    def log_message(self, message):\n",
    "        print(message, file=self.log_file, flush=True)\n",
    "        print(message, file=sys.stdout, flush=True)\n",
    "\n",
    "    def transform(self, col_selector: List[str], df: \"cudf.DataFrame\") -> \"cudf.DataFrame\":\n",
    "        start_time = time.time()\n",
    "        self.log_message(f\"Début de QueryFeast.transform() à {start_time}\")\n",
    "        self.logger.error(f\"Debut Feast {time.time()}\")\n",
    "        result = super().transform(col_selector, df)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        self.log_message(f\"Fin de QueryFeast.transform(). Durée: {duration:.4f} secondes\")\n",
    "        self.logger.error(f\"Fin Feast {time.time()}\")\n",
    "        return result\n",
    "\n",
    "    def compute_output_schema(self, input_schema: Schema, col_selector: List[str], prev_output_schema: Schema = None) -> Schema:\n",
    "        start_time = time.time()\n",
    "        self.log_message(f\"Début de QueryFeast.compute_output_schema() à {start_time}\")\n",
    "        \n",
    "        result = super().compute_output_schema(input_schema, col_selector, prev_output_schema)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        self.log_message(f\"Fin de QueryFeast.compute_output_schema(). Durée: {duration:.4f} secondes\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'log_file'):\n",
    "            self.log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ac139cf9-ebc9-4934-babf-5403b922df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2024-08-30 14:54:56+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32muser_features\u001b[0m from \u001b[1m\u001b[32m2025-01-01 01:01:01+00:00\u001b[0m to \u001b[1m\u001b[32m2024-08-30 14:54:56+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) 2nd_last_product_code, 2nd_last_product_type, 2nd_popular_department_no, 2nd_popular_product_type, 2nd_popular_section_no, Active, FN with unsupported characters which will be renamed to nd_last_product_code, nd_last_product_type, nd_popular_department_no, nd_popular_product_type, nd_popular_section_no, active, fn in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 78). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_nrnrr16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_nrnrr16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2024-08-30 14:55:09+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mitem_features\u001b[0m from \u001b[1m\u001b[32m2025-01-01 01:01:01+00:00\u001b[0m to \u001b[1m\u001b[32m2024-08-30 14:55:09+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  FN  Active  club_member_status  fashion_news_frequency  \\\n",
      "0       11   4       3                   3                       4   \n",
      "\n",
      "   postal_code  popular_product_type  2nd_popular_product_type  \\\n",
      "0           99                    14                         6   \n",
      "\n",
      "   popular_department_no  2nd_popular_department_no  popular_section_no  \\\n",
      "0                     13                         35                   8   \n",
      "\n",
      "   2nd_popular_section_no  last_product_code  2nd_last_product_code  \\\n",
      "0                       4                 55                    382   \n",
      "\n",
      "   last_product_type  2nd_last_product_type       age  frequency    amount  \\\n",
      "0                 17                      7 -0.544461   1.025946  0.784323   \n",
      "\n",
      "    recency  \n",
      "0 -0.594213  \n"
     ]
    }
   ],
   "source": [
    "from merlin.core.dispatch import make_df\n",
    "from merlin.systems.dag.ops.feast import QueryFeast\n",
    "from nvtabular import ColumnSelector, Workflow, Dataset\n",
    "\n",
    "\n",
    "#Test input\n",
    "request = make_df({\"user_id\": [11]})\n",
    "request[\"user_id\"] = request[\"user_id\"].astype(np.int32)\n",
    "test_dataset = Dataset(request)\n",
    "\n",
    "\n",
    "# Embedding retrieval >> TimerOperator('Début du worklow')\n",
    "user_attributes = [\"user_id\"] >> EnhancedTimedQueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    view=\"user_features\",\n",
    "    column=\"user_id\",\n",
    "    include_id=True,\n",
    ")\n",
    "\n",
    "# >> TimerOperator('Récupération des attributes') \n",
    "nvt_workflow = Workflow.load(os.path.join(MODELS_FOLDER, 'general_workflow'))\n",
    "user_subgraph = nvt_workflow.get_subworkflow(\"user\")\n",
    "user_features = user_attributes >> TransformWorkflow(user_subgraph) \n",
    "\n",
    "configure_tensorflow()\n",
    "\n",
    "topk_retrieval = int(\n",
    "    os.environ.get(\"topk_retrieval\", \"100\")\n",
    ")\n",
    "# Predictensorflow 1 \n",
    "retrieval = (\n",
    "    user_features\n",
    "    #>> TimerOperator('Transformation des features user') \n",
    "    >> PredictTensorflow(retrieval_model_path)\n",
    "    >> QueryFaiss(faiss_index_path, topk=topk_retrieval)\n",
    ")\n",
    "\n",
    "# >> TimerOperator('Retrieval Two Tower') \n",
    "item_attributes = retrieval[\"candidate_ids\"] >>  QueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    view=\"item_features\",\n",
    "    column=\"candidate_ids\",\n",
    "    #output_prefix=\"item\",\n",
    "    include_id=True,\n",
    ")\n",
    "\n",
    "\n",
    "output = TEST_workflow.fit_transform(test_dataset)\n",
    "\n",
    "\n",
    "print(output.to_ddf().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c056fb8-0c32-457e-ba79-b80fa5bc5107",
   "metadata": {},
   "source": [
    "Premier opérateur : récupération des features brut d'un client à partir d'un user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e30fbe0a-2d4e-48eb-be43-53a676994262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2024-08-30 15:37:52+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32muser_features\u001b[0m from \u001b[1m\u001b[32m2025-01-01 01:01:01+00:00\u001b[0m to \u001b[1m\u001b[32m2024-08-30 15:37:52+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    }
   ],
   "source": [
    "from merlin.systems.dag.ops.feast import QueryFeast \n",
    "\n",
    "user_attributes = [\"user_id\"] >> EnhancedTimedQueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    view=\"user_features\",\n",
    "    column=\"user_id\",\n",
    "    include_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7138f035-83d8-44ca-adf0-2bfe6b5917f5",
   "metadata": {},
   "source": [
    "Préparation des données pour le Two Tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1d71fbda-343c-412e-8dc1-e45886955400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular import Workflow\n",
    "# Premier workflow\n",
    "nvt_workflow = Workflow.load(os.path.join(MODELS_FOLDER, 'general_workflow'))\n",
    "user_subgraph = nvt_workflow.get_subworkflow(\"user\")\n",
    "user_features = user_attributes  >>  TransformWorkflow(user_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f1a6d5d-ac22-4931-96bf-01e3bdb7725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.dlpack.dlpack.from_dlpack(dlcapsule)>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prevent TF to claim all GPU memory\n",
    "from merlin.dataloader.tf_utils import configure_tensorflow\n",
    "\n",
    "configure_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edeb3-54f8-463a-bb93-2cb4668eb329",
   "metadata": {},
   "source": [
    "On récupère les items candidats en comparant l'embedding du client aux embeddings des produits via faiss.\n",
    "\n",
    "On récupère ensuite les features de ces items dans feast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a72b4c04-fbd1-4e08-8752-3284e742e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) 2nd_last_product_code, 2nd_last_product_type, 2nd_popular_department_no, 2nd_popular_product_type, 2nd_popular_section_no, Active, FN with unsupported characters which will be renamed to nd_last_product_code, nd_last_product_type, nd_popular_department_no, nd_popular_product_type, nd_popular_section_no, active, fn in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 78). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_bfchr44/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_bfchr44/assets\n"
     ]
    }
   ],
   "source": [
    "topk_retrieval = int(\n",
    "    os.environ.get(\"topk_retrieval\", \"100\")\n",
    ")\n",
    "# Predictensorflow 1 \n",
    "retrieval = (\n",
    "    user_features\n",
    "    >> PredictTensorflow(retrieval_model_path)\n",
    "    >> QueryFaiss(faiss_index_path, topk=topk_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d1e5f450-b8de-4a4a-9de9-159fbc2b0a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2024-08-30 15:38:05+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mitem_features\u001b[0m from \u001b[1m\u001b[32m2025-01-01 01:01:01+00:00\u001b[0m to \u001b[1m\u001b[32m2024-08-30 15:38:05+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n"
     ]
    }
   ],
   "source": [
    "item_attributes = retrieval[\"candidate_ids\"]   >>  EnhancedTimedQueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    view=\"item_features\",\n",
    "    column=\"candidate_ids\",\n",
    "    #output_prefix=\"item\",\n",
    "    include_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b2f5bc83-f349-4cda-aa00-a034e8e7bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_subgraph = nvt_workflow.get_subworkflow(\"item\")\n",
    "item_features = item_attributes  >> TransformWorkflow(item_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e4645ad6-5368-4152-8868-46d58c55ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_to_unroll = [\n",
    "    \"user_id\",\n",
    "    \"FN\",\n",
    "    \"Active\",\n",
    "    \"club_member_status\",\n",
    "    \"fashion_news_frequency\",\n",
    "    \"age\",\n",
    "    \"postal_code\",\n",
    "    \"recency\",\n",
    "    \"frequency\",\n",
    "    \"amount\", 'popular_product_type', '2nd_popular_product_type', 'popular_department_no', '2nd_popular_department_no', 'popular_section_no', '2nd_popular_section_no', 'last_product_code', '2nd_last_product_code', 'last_product_type', '2nd_last_product_type']\n",
    "\n",
    "combined_features = item_features  >> UnrollFeatures(\n",
    "    \"item_id\", user_features[user_features_to_unroll]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feff570-e988-4a57-866c-bb4e20fba3af",
   "metadata": {},
   "source": [
    "Scoring avec le modèle DLRM sauvegardé précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e2ceb3ea-d028-4f5e-b787-9cc45f822437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) 2nd_last_product_code, 2nd_last_product_type, 2nd_popular_department_no, 2nd_popular_product_type, 2nd_popular_section_no, Active, FN, Time_Weighted_Purchased with unsupported characters which will be renamed to nd_last_product_code, nd_last_product_type, nd_popular_department_no, nd_popular_product_type, nd_popular_section_no, active, fn, time_weighted_purchased in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 172). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgj0cxcdf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgj0cxcdf/assets\n"
     ]
    }
   ],
   "source": [
    "ranking = combined_features >> PredictTensorflow(ranking_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b5fcf642-f430-436a-9522-cedfd298bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k=12\n",
    "ordering = combined_features[\"item_id\"] >>  SoftmaxSampling(\n",
    "    relevance_col=ranking[\"Target/binary_output\"], topk=top_k, temperature=0.00000001\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7d7c2-4370-4f05-a56f-450dcf126d32",
   "metadata": {},
   "source": [
    "from merlin.core.dispatch import make_df\n",
    "from merlin.systems.dag.ops.feast import QueryFeast\n",
    "from nvtabular import ColumnSelector, Workflow, Dataset\n",
    "\n",
    "#Test input\n",
    "request = make_df({\"user_id\": [11]})\n",
    "request[\"user_id\"] = request[\"user_id\"].astype(np.int32)\n",
    "test_dataset = Dataset(request)\n",
    "\n",
    "# Exécuter la pipeline sur les données de test\n",
    "similarity_workflow = Workflow(ordering)\n",
    "output = similarity_workflow.transform(test_dataset)\n",
    "\n",
    "\n",
    "print(output.to_ddf().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b32f8e-2a84-4711-baaa-af824f1b7d1c",
   "metadata": {},
   "source": [
    "## Sauvegarde de la pipeline complète"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632f47c-e3a9-4ed8-99ce-c6451de900c6",
   "metadata": {},
   "source": [
    "Create folder to export graphs and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09724c-0e9c-4c9c-bccb-862de930a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"/root/Triton_models\"):\n",
    "    os.makedirs(os.path.join('/root/Triton_models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fa00b-774a-43a0-ae7d-10abe9737565",
   "metadata": {},
   "source": [
    "Création du schema de l'input qu'on va donner à Triton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6d82d0e2-cb3d-435b-9a1f-adfeb4c29a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='int32', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_id', 'tags': set(), 'properties': {}, 'dtype': DType(name='int32', element_type=<ElementType.Int: 'int'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=None)), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_schema = Schema(\n",
    "    [\n",
    "        ColumnSchema(\"user_id\", dtype=np.int32),\n",
    "    ]\n",
    ")\n",
    "request_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e927731-cd23-4001-b3b2-23a988ad97f6",
   "metadata": {},
   "source": [
    "Création de l'ensemble python (la pipeline au complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "67faa682-a4e7-4077-b525-e993fac39d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ordered_ids', 'ordered_scores']\n",
      "CPU times: user 32.6 s, sys: 254 ms, total: 32.9 s\n",
      "Wall time: 726 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define the path where all the models and config files exported to\n",
    "export_path = os.path.join('/root/Triton_models_test_operateur_perso')\n",
    "\n",
    "ensemble = Ensemble(ordering, request_schema)\n",
    "ens_config, node_configs = ensemble.export(export_path)\n",
    "\n",
    "# return the output column name\n",
    "outputs = ensemble.graph.output_schema.column_names\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1c0083-d134-49b1-a2d6-c3786d19fe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton_models_test_operateur_perso/\n",
      "├─0_transformworkflowtriton/\n",
      "│ ├─1/\n",
      "│ │ ├─__pycache__/\n",
      "│ │ │ └─model.cpython-310.pyc\n",
      "│ │ ├─model.py\n",
      "│ │ └─workflow/\n",
      "│ │   ├─categories/\n",
      "│ │   │ ├─unique.2nd_last_product_code.parquet\n",
      "│ │   │ ├─unique.2nd_last_product_type.parquet\n",
      "│ │   │ ├─unique.2nd_popular_department_no.parquet\n",
      "│ │   │ ├─unique.2nd_popular_product_type.parquet\n",
      "│ │   │ ├─unique.2nd_popular_section_no.parquet\n",
      "│ │   │ ├─unique.Active.parquet\n",
      "│ │   │ ├─unique.FN.parquet\n",
      "│ │   │ ├─unique.club_member_status.parquet\n",
      "│ │   │ ├─unique.fashion_news_frequency.parquet\n",
      "│ │   │ └─unique.last_product_code.parquet\n",
      "│ │   ├─metadata.json\n",
      "│ │   └─workflow.pkl\n",
      "│ └─config.pbtxt\n",
      "├─1_predicttensorflowtriton/\n",
      "│ ├─1/\n",
      "│ │ └─model.savedmodel/\n",
      "│ │   ├─.merlin/\n",
      "│ │   │ ├─input_schema.json\n",
      "│ │   │ └─output_schema.json\n",
      "│ │   ├─assets/\n",
      "│ │   ├─fingerprint.pb\n",
      "│ │   ├─keras_metadata.pb\n",
      "│ │   ├─saved_model.pb\n",
      "│ │   └─variables/\n",
      "│ │     ├─variables.data-00000-of-00001\n",
      "│ │     └─variables.index\n",
      "│ └─config.pbtxt\n",
      "├─2_transformworkflowtriton/\n",
      "│ ├─1/\n",
      "│ │ ├─__pycache__/\n",
      "│ │ │ └─model.cpython-310.pyc\n",
      "│ │ ├─model.py\n",
      "│ │ └─workflow/\n",
      "│ │   ├─categories/\n",
      "│ │   │ ├─unique.colour_group_code.parquet\n",
      "│ │   │ ├─unique.department_no.parquet\n",
      "│ │   │ ├─unique.detail_desc.parquet\n",
      "│ │   │ ├─unique.garment_group_no.parquet\n",
      "│ │   │ ├─unique.graphical_appearance_no.parquet\n",
      "│ │   │ ├─unique.index_code.parquet\n",
      "│ │   │ ├─unique.index_group_no.parquet\n",
      "│ │   │ ├─unique.perceived_colour_master_id.parquet\n",
      "│ │   │ ├─unique.perceived_colour_value_id.parquet\n",
      "│ │   │ └─unique.prod_name.parquet\n",
      "│ │   ├─metadata.json\n",
      "│ │   └─workflow.pkl\n",
      "│ └─config.pbtxt\n",
      "├─3_predicttensorflowtriton/\n",
      "│ ├─1/\n",
      "│ │ └─model.savedmodel/\n",
      "│ │   ├─.merlin/\n",
      "│ │   │ ├─input_schema.json\n",
      "│ │   │ └─output_schema.json\n",
      "│ │   ├─assets/\n",
      "│ │   ├─fingerprint.pb\n",
      "│ │   ├─keras_metadata.pb\n",
      "│ │   ├─saved_model.pb\n",
      "│ │   └─variables/\n",
      "│ │     ├─variables.data-00000-of-00001\n",
      "│ │     └─variables.index\n",
      "│ └─config.pbtxt\n",
      "└─executor_model/\n",
      "  ├─1/\n",
      "  │ ├─__pycache__/\n",
      "  │ │ └─model.cpython-310.pyc\n",
      "  │ ├─ensemble/\n",
      "  │ │ ├─ensemble.pkl\n",
      "  │ │ ├─index.faiss\n",
      "  │ │ └─metadata.json\n",
      "  │ └─model.py\n",
      "  └─config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "sd.seedir( os.path.join('/root/Triton_models_test_operateur_perso'), style='lines', itemlimit=10, depthlimit=5, sort=True) #exclude_folders=['.ipynb_checkpoints', '__pycache__']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c480b-bff9-4264-acfc-dbc42654fd5a",
   "metadata": {},
   "source": [
    "## Démarrage du Triton Server\n",
    "\n",
    "Let's clean some useless files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a8696c3c-2286-48e2-ab33-002cda169c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "export_path = os.path.join('/root/Triton_models_test_operateur_perso')\n",
    "\n",
    "def remove_checkpoints(dir_path):\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == '.ipynb_checkpoints':\n",
    "                dir_to_remove = os.path.join(root, dir_name)\n",
    "                print(f\"Removing: {dir_to_remove}\")\n",
    "                shutil.rmtree(dir_to_remove)\n",
    "\n",
    "remove_checkpoints(export_path)\n",
    "\n",
    "#sd.seedir(export_path, style='lines', itemlimit=10, depthlimit=5, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fbcfa2-d335-4f72-a595-4f588cc5fb89",
   "metadata": {},
   "source": [
    "Pour démarrer Triton Inference Server, il faut executer la commande suivande dans un terminale dans ce conteneur :\n",
    "\n",
    "tritonserver --model-repository=/root/Triton_models/ --backend-config=tensorflow,version=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffbe71-b0fe-4646-8934-bcc2eb106a96",
   "metadata": {},
   "source": [
    "Il faut attendre d'avoir tous les modèles ready dans le terminal avant d'executer les test (cela peut être vraiment long 20-30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dafa4a-f8d3-438d-a0cc-86a9968dda14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id\n",
      "0        9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ordered_ids': array([[837283001, 812530002, 912075004, 867948001, 830016003, 915412002,\n",
       "         873279001, 898703001, 873279003, 855769002, 909916002, 772785005]],\n",
       "       dtype=int32),\n",
       " 'ordered_scores': array([[0.97283494, 0.9176917 , 0.967815  , 0.99024385, 0.9676408 ,\n",
       "         0.95743316, 0.9999999 , 0.9802405 , 0.9999999 , 0.9687073 ,\n",
       "         0.99999964, 0.9999497 ]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data for request\n",
    "\n",
    "from merlin.core.dispatch import make_df\n",
    "\n",
    "# create a request to be sent to TIS\n",
    "request = make_df({\"user_id\": [9]})\n",
    "request[\"user_id\"] = request[\"user_id\"].astype(np.int32)\n",
    "print(request)\n",
    "\n",
    "outputs = ['ordered_ids', 'ordered_scores']\n",
    "\n",
    "request_schema = Schema(\n",
    "    [\n",
    "        ColumnSchema(\"user_id\", dtype=np.int32),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = send_triton_request(request_schema, request, outputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1120e1-6427-4233-afa8-fa520fce1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id\n",
      "0        9\n"
     ]
    }
   ],
   "source": [
    "from merlin.core.dispatch import make_df\n",
    "\n",
    "# create a request to be sent to TIS\n",
    "request = make_df({\"user_id\": [9]})\n",
    "request[\"user_id\"] = request[\"user_id\"].astype(np.int32)\n",
    "print(request)\n",
    "\n",
    "outputs = ['ordered_ids', 'ordered_scores']\n",
    "\n",
    "request_schema = Schema(\n",
    "    [\n",
    "        ColumnSchema(\"user_id\", dtype=np.int32),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3246ed93-d1f9-433b-ba47-fd39eae38c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 ms, sys: 3.19 ms, total: 16.3 ms\n",
      "Wall time: 792 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ordered_ids': array([[873884006, 781613013, 914351004, 673677011, 873279001, 911870009,\n",
       "         859805007, 885910001, 873679001, 781613015, 858313001, 749699024]],\n",
       "       dtype=int32),\n",
       " 'ordered_scores': array([[0.9886706 , 0.9668843 , 0.97886753, 0.99835396, 0.9999999 ,\n",
       "         0.99999976, 0.9623392 , 0.99990916, 0.9898747 , 0.975149  ,\n",
       "         0.9585596 , 0.930302  ]], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = send_triton_request(request_schema, request, outputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993cb8f0-b31a-48ed-8259-ab07963a6d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
