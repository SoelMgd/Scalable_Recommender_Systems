{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b1dd5b6-c6a3-4d3f-8cc3-57324c9b6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "import numpy as np\n",
    "\n",
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42396666-ffc6-4d81-a8c3-2abc56156f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cudf' from '/usr/local/lib/python3.10/dist-packages/cudf/__init__.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/root/Data/Row/\")\n",
    "DATA_FOLDER = os.environ.get(\"DATA_FOLDER\", \"/root/Data/\")\n",
    "MODELS_FOLDER = os.environ.get(\"MODELS\", \"/root/Models/\")\n",
    "PROCESSED_FOLDER = os.environ.get(\"PROCESSED_FOLDER\", \"/root/Data/Processed/\")\n",
    "feature_repo_path = os.environ.get(\"FEAST_PATH\", \"/root/Data/feast_repo/feature_repo\")\n",
    "\n",
    "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", 512))\n",
    "from merlin.core.dispatch import get_lib\n",
    "df_lib = get_lib()\n",
    "df_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274f44f-8aa6-4c67-b4bd-9621ed7a8dd8",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_processed = pd.read_csv('/root/Data/Plot/train_numeric')\n",
    "test_processed = pd.read_csv('/root/Data/Plot/test_numeric')\n",
    "ytest = pd.read_csv('/root/Data/Plot/ytest_numeric')\n",
    "ytrain = pd.read_csv('/root/Data/Plot/ytrain_numeric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f98e790-b4ea-4e07-a7e0-e6ef34b5061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_full = Dataset(os.path.join(PROCESSED_FOLDER, \"train_processed\", \"*.parquet\")).compute()\n",
    "test_processed_full = Dataset(os.path.join(PROCESSED_FOLDER, \"test_processed\", \"*.parquet\")).compute()\n",
    "\n",
    "ytest = test_processed_full[['Target']].to_pandas()\n",
    "ytrain = train_processed_full[['Target']].to_pandas()\n",
    "train_processed = train_processed_full.drop('Target', axis=1).to_pandas()\n",
    "test_processed = test_processed_full.drop('Target', axis=1).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23c14749-4076-4da9-b951-e68e991d9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_full.to_csv('train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e1ae1c2-2b15-4a52-9753-b112200938c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'product_code', 'prod_name', 'product_type_no',\n",
       "       'graphical_appearance_no', 'colour_group_code', 'product_group_name',\n",
       "       'perceived_colour_value_id', 'perceived_colour_master_id',\n",
       "       'department_no', 'index_code', 'index_group_no', 'section_no',\n",
       "       'garment_group_no', 'detail_desc', 'Time_Weighted_Purchased',\n",
       "       'count_7d_purchased', 'count_30d_purchased', 'user_id', 'FN', 'Active',\n",
       "       'club_member_status', 'fashion_news_frequency', 'postal_code',\n",
       "       'popular_product_type', '2nd_popular_product_type',\n",
       "       'popular_department_no', '2nd_popular_department_no',\n",
       "       'popular_section_no', '2nd_popular_section_no', 'last_product_code',\n",
       "       '2nd_last_product_code', 'last_product_type', '2nd_last_product_type',\n",
       "       'age', 'frequency', 'amount', 'recency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3e6e3a-7424-4f5e-b899-9f1f143eec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420582</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420583</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420584</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420585</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420586</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420587 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target\n",
       "0            1\n",
       "1            0\n",
       "2            0\n",
       "3            1\n",
       "4            0\n",
       "...        ...\n",
       "420582       1\n",
       "420583       0\n",
       "420584       0\n",
       "420585       0\n",
       "420586       1\n",
       "\n",
       "[420587 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97f2a8a3-0246-4ff2-85d2-c03259609975",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['item_id', 'user_id']\n",
    "train_set = train_processed.drop(columns=to_drop)\n",
    "test_set = test_processed.drop(columns=to_drop)\n",
    "ytest = ytest #.drop(columns=['Unnamed: 0'])\n",
    "ytrain = ytrain #.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ce6ebe3-e2bb-4807-b3fe-9c4eb2117ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77b6e73b-488b-4367-8b5b-e402d1888919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0         511039\n",
       "1         470328\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0edb857f-90be-45a8-81ab-e8fa0cfee8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23417"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8044b417-6a3f-4108-886b-cc05d946016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981367 981367 981367\n"
     ]
    }
   ],
   "source": [
    "print(len(train_processed_full), len(train_set), len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e08be81-d0c7-4d05-9949-1b5077922e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2024/233267785.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(train_set, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81    218849\n",
      "           1       0.84      0.70      0.76    201738\n",
      "\n",
      "    accuracy                           0.79    420587\n",
      "   macro avg       0.80      0.79      0.79    420587\n",
      "weighted avg       0.80      0.79      0.79    420587\n",
      "\n",
      "0.7857757868186614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=10) #, class_weight='balanced_subsample'\n",
    "model.fit(train_set, ytrain)\n",
    "y_pred = model.predict(test_set)\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(ytest, y_pred))\n",
    "print(roc_auc_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bddf3d4-d9eb-4174-8354-7e25ed8adbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "precision = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['precision']\n",
    "recall = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['recall']\n",
    "auc = roc_auc_score(ytest, y_pred)\n",
    "loss = None  # Vous pouvez calculer une autre métrique de perte si nécessaire\n",
    "\n",
    "# Formatage des résultats\n",
    "results = f\"\"\"\n",
    "RandomForest\n",
    "val_loss:{loss}\n",
    "val_auc:{auc}\n",
    "val_precision:{precision}\n",
    "val_recall:{recall}\n",
    "\"\"\"\n",
    "\n",
    "# Ajout des résultats au fichier\n",
    "with open('results.txt', 'a') as file:\n",
    "    file.write(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88a717c4-f808-4401-ba33-b8870c968520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postal_code                   0.129420\n",
      "Time_Weighted_Purchased       0.101539\n",
      "count_30d_purchased           0.091878\n",
      "count_7d_purchased            0.054682\n",
      "recency                       0.043049\n",
      "frequency                     0.042978\n",
      "2nd_last_product_code         0.036101\n",
      "last_product_code             0.034749\n",
      "age                           0.030552\n",
      "amount                        0.028955\n",
      "2nd_popular_department_no     0.027406\n",
      "detail_desc                   0.025974\n",
      "2nd_popular_product_type      0.025858\n",
      "department_no                 0.025617\n",
      "popular_department_no         0.024682\n",
      "prod_name                     0.024490\n",
      "product_code                  0.024396\n",
      "2nd_last_product_type         0.024124\n",
      "last_product_type             0.024094\n",
      "2nd_popular_section_no        0.022244\n",
      "popular_product_type          0.021849\n",
      "popular_section_no            0.018345\n",
      "product_type_no               0.015061\n",
      "product_group_name            0.013159\n",
      "colour_group_code             0.012790\n",
      "section_no                    0.012717\n",
      "garment_group_no              0.012655\n",
      "perceived_colour_master_id    0.010625\n",
      "graphical_appearance_no       0.007987\n",
      "perceived_colour_value_id     0.007430\n",
      "index_code                    0.006912\n",
      "index_group_no                0.004408\n",
      "fashion_news_frequency        0.003964\n",
      "Active                        0.003850\n",
      "FN                            0.003741\n",
      "club_member_status            0.001721\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importances, index=train_set.columns).sort_values(ascending=False)\n",
    "\n",
    "print(forest_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93addd5c-2926-4bd8-a271-1227953935ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances.to_csv('feature_importances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cfd5ed6-e5e6-434d-8671-982677441ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81    218849\n",
      "           1       0.81      0.72      0.76    201738\n",
      "\n",
      "    accuracy                           0.79    420587\n",
      "   macro avg       0.79      0.78      0.78    420587\n",
      "weighted avg       0.79      0.79      0.79    420587\n",
      "\n",
      "0.7843517173560879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=0, n_estimators=40, max_depth=10) \n",
    "model.fit(train_set, ytrain)\n",
    "y_pred = model.predict(test_set)\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(ytest, y_pred))\n",
    "print(roc_auc_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d5091f-ac06-4cad-bd35-a9879ba4b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......max_depth=10, n_estimators=50, random_state=0; total time= 5.0min\n",
      "[CV] END ......max_depth=10, n_estimators=50, random_state=0; total time= 5.0min\n",
      "[CV] END .....max_depth=10, n_estimators=100, random_state=0; total time=10.2min\n",
      "[CV] END .....max_depth=10, n_estimators=100, random_state=0; total time=10.2min\n",
      "[CV] END ......max_depth=20, n_estimators=50, random_state=0; total time=20.4min\n",
      "[CV] END ......max_depth=20, n_estimators=50, random_state=0; total time=20.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....max_depth=20, n_estimators=100, random_state=0; total time=40.5min\n",
      "[CV] END .....max_depth=20, n_estimators=100, random_state=0; total time=41.1min\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82    218849\n",
      "           1       0.82      0.74      0.78    201738\n",
      "\n",
      "    accuracy                           0.80    420587\n",
      "   macro avg       0.80      0.80      0.80    420587\n",
      "weighted avg       0.80      0.80      0.80    420587\n",
      "\n",
      "Meilleurs paramètres trouvés : {'max_depth': 10, 'n_estimators': 100, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Définir les hyperparamètres à explorer\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    #'min_samples_split': [5],\n",
    "    #'min_samples_leaf': [1],\n",
    "    #'class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'random_state': [0],\n",
    "    #'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Créer un modèle RandomForestClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Configurer GridSearchCV pour optimiser le rappel\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=2,  # Utiliser 3-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec GridSearchCV\n",
    "grid_search.fit(train_set, ytrain)\n",
    "\n",
    "# Extraire le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prédire avec le meilleur modèle\n",
    "y_pred = best_model.predict(test_set)\n",
    "\n",
    "# Calculer les métriques\n",
    "precision = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['precision']\n",
    "recall = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['recall']\n",
    "auc = roc_auc_score(ytest, y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(ytest, y_pred))\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7165a3f-d58b-487d-b19f-66430ffa8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.7831328842826668, 'recall': 0.8521354906807891, 'f1-score': 0.8161783531481617, 'support': 218849}, '1': {'precision': 0.8226411991998027, 'recall': 0.7440095569501036, 'f1-score': 0.7813520808551953, 'support': 201738}, 'accuracy': 0.8002720007988835, 'macro avg': {'precision': 0.8028870417412348, 'recall': 0.7980725238154464, 'f1-score': 0.7987652170016785, 'support': 420587}, 'weighted avg': {'precision': 0.8020833711849086, 'recall': 0.8002720007988835, 'f1-score': 0.7994736463459104, 'support': 420587}}\n",
      "0.7980725238154462\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred, output_dict=True))\n",
    "print(roc_auc_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f689d-4add-4bbc-9aa3-212b0f26597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation de SVM:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_set, test_set, np.ravel(ytrain), np.ravel(ytest)\n",
    "\n",
    "\n",
    "# Liste des classifieurs à tester\n",
    "classifiers = [\n",
    "    #(\"Random Forest\", RandomForestClassifier(n_jobs=-1, n_estimators=10)),\n",
    "    (\"SVM\", SVC(probability=True)),\n",
    "    #(\"KNN\", KNeighborsClassifier()),\n",
    "    #(\"Logistic Regression\", LogisticRegression())\n",
    "]\n",
    "\n",
    "# Fonction pour évaluer un modèle\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Vérifier si le modèle a une méthode predict_proba\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    else:\n",
    "        print(\"ROC AUC: Not available for this model\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Évaluation de chaque classifieur\n",
    "for name, clf in classifiers:\n",
    "    print(f\"Évaluation de {name}:\")\n",
    "    evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa708795-1d0d-4ebb-8c21-4269a3ed6069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation de Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81    218849\n",
      "           1       0.84      0.70      0.76    201738\n",
      "\n",
      "    accuracy                           0.79    420587\n",
      "   macro avg       0.80      0.79      0.79    420587\n",
      "weighted avg       0.80      0.79      0.79    420587\n",
      "\n",
      "ROC AUC: 0.8677\n",
      "\n",
      "\n",
      "Évaluation de KNN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68    218849\n",
      "           1       0.65      0.63      0.64    201738\n",
      "\n",
      "    accuracy                           0.66    420587\n",
      "   macro avg       0.66      0.66      0.66    420587\n",
      "weighted avg       0.66      0.66      0.66    420587\n",
      "\n",
      "ROC AUC: 0.7147\n",
      "\n",
      "\n",
      "Évaluation de Logistic Regression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60    218849\n",
      "           1       0.56      0.56      0.56    201738\n",
      "\n",
      "    accuracy                           0.58    420587\n",
      "   macro avg       0.58      0.58      0.58    420587\n",
      "weighted avg       0.58      0.58      0.58    420587\n",
      "\n",
      "ROC AUC: 0.6145\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_set, test_set, np.ravel(ytrain), np.ravel(ytest)\n",
    "\n",
    "\n",
    "# Liste des classifieurs à tester\n",
    "classifiers = [\n",
    "    (\"Random Forest\", RandomForestClassifier(n_jobs=-1, n_estimators=10)),\n",
    "    #(\"SVM\", SVC(probability=True)),\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"Logistic Regression\", LogisticRegression())\n",
    "]\n",
    "\n",
    "# Fonction pour évaluer un modèle\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Vérifier si le modèle a une méthode predict_proba\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    else:\n",
    "        print(\"ROC AUC: Not available for this model\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Évaluation de chaque classifieur\n",
    "for name, clf in classifiers:\n",
    "    print(f\"Évaluation de {name}:\")\n",
    "    evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77629ce0-e2ba-4f96-b6ab-ad028bc5fafa",
   "metadata": {},
   "source": [
    "# Grid search pour le recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffb4a73-8f2d-4a90-ba0b-aaaad7597148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82    218849\n",
      "           1       0.83      0.75      0.79    201738\n",
      "\n",
      "    accuracy                           0.81    420587\n",
      "   macro avg       0.81      0.81      0.81    420587\n",
      "weighted avg       0.81      0.81      0.81    420587\n",
      "\n",
      "Meilleurs paramètres trouvés : {'class_weight': 'balanced_subsample', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Définir les hyperparamètres à explorer\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [30],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],\n",
    "    #'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "#{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 40}\n",
    "\n",
    "# Créer un modèle RandomForestClassifier\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Configurer GridSearchCV pour optimiser le rappel\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(recall_score),\n",
    "    cv=2,  # Utiliser 3-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec GridSearchCV\n",
    "grid_search.fit(train_set, ytrain)\n",
    "\n",
    "# Extraire le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prédire avec le meilleur modèle\n",
    "y_pred = best_model.predict(test_set)\n",
    "\n",
    "# Calculer les métriques\n",
    "precision = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['precision']\n",
    "recall = classification_report(ytest, y_pred, output_dict=True)['weighted avg']['recall']\n",
    "auc = roc_auc_score(ytest, y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(ytest, y_pred))\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a6f82c8-0634-47e4-9b38-5d342aed361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.788121312476218, 'recall': 0.8612330876540446, 'f1-score': 0.823056768558952, 'support': 218849}, '1': {'precision': 0.8326186644326374, 'recall': 0.7488276873965242, 'f1-score': 0.7885033953243175, 'support': 201738}, 'accuracy': 0.8073169165951396, 'macro avg': {'precision': 0.8103699884544278, 'recall': 0.8050303875252844, 'f1-score': 0.8057800819416348, 'support': 420587}, 'weighted avg': {'precision': 0.8094648318645591, 'recall': 0.8073169165951396, 'f1-score': 0.8064829600256196, 'support': 420587}}\n",
      "0.8050303875252843\n",
      "[CV] END class_weight=balanced, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END class_weight=balanced, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  10.9s\n",
      "[CV] END class_weight=balanced_subsample, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.5s\n",
      "[CV] END class_weight=balanced_subsample, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.8s\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred, output_dict=True))\n",
    "print(roc_auc_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7722c4-de6f-4569-a6af-71fd64a916a1",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db552f22-715c-4c57-aa3d-19980618a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afe2f91-81ca-4f6c-8e3d-7a1529a0900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée: [0.90471229 0.90399891 0.90439405 0.90392881 0.90516731]\n",
      "Score moyen: 0.904 (+/- 0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1383/3446256361.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "/tmp/ipykernel_1383/3446256361.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "/tmp/ipykernel_1383/3446256361.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "/tmp/ipykernel_1383/3446256361.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "/tmp/ipykernel_1383/3446256361.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance des features:\n",
      "                       feature  importance\n",
      "19         count_30d_purchased    0.110228\n",
      "8                  postal_code    0.078685\n",
      "20          count_7d_purchased    0.063564\n",
      "23                     recency    0.028575\n",
      "24                   frequency    0.026329\n",
      "21     Time_Weighted_Purchased    0.024660\n",
      "1           product_group_name    0.007296\n",
      "22                         age    0.006581\n",
      "31      2nd_popular_section_no    0.005939\n",
      "30          popular_section_no    0.005439\n",
      "0                    prod_name    0.005427\n",
      "25                      amount    0.005190\n",
      "3                  detail_desc    0.005089\n",
      "9                 product_code    0.004580\n",
      "18            garment_group_no    0.004125\n",
      "17                  section_no    0.003772\n",
      "27    2nd_popular_product_type    0.003727\n",
      "28       popular_department_no    0.003523\n",
      "29   2nd_popular_department_no    0.003340\n",
      "10             product_type_no    0.003311\n",
      "15               department_no    0.003309\n",
      "26        popular_product_type    0.003170\n",
      "32           last_product_code    0.002990\n",
      "33       2nd_last_product_code    0.002935\n",
      "35       2nd_last_product_type    0.002216\n",
      "34           last_product_type    0.002064\n",
      "2                   index_code    0.001436\n",
      "16              index_group_no    0.001024\n",
      "6           club_member_status    0.000881\n",
      "12           colour_group_code    0.000847\n",
      "11     graphical_appearance_no    0.000598\n",
      "5                       Active    0.000473\n",
      "4                           FN    0.000429\n",
      "7       fashion_news_frequency    0.000365\n",
      "14  perceived_colour_master_id    0.000279\n",
      "13   perceived_colour_value_id    0.000173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Supposons que X soit votre ensemble de features et y vos labels\n",
    "X = pd.concat([train_set, test_set])\n",
    "y = pd.concat([ytrain, ytest])\n",
    "\n",
    "# Définir le modèle\n",
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "\n",
    "# Définir la validation croisée\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Effectuer la validation croisée pour le score\n",
    "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"Scores de validation croisée: {cv_scores}\")\n",
    "print(f\"Score moyen: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Calculer l'importance des features avec permutation importance\n",
    "feature_importance = np.zeros(X.shape[1])\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculer l'importance des features pour cette itération\n",
    "    perm_importance = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42)\n",
    "    feature_importance += perm_importance.importances_mean\n",
    "\n",
    "# Moyenner l'importance des features sur toutes les itérations\n",
    "feature_importance /= cv.n_splits\n",
    "\n",
    "# Créer un DataFrame avec les importances des features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# Trier les features par importance décroissante\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportance des features:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4526968f-113c-4916-8d68-7fa053bb627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(os.path.join(PROCESSED_FOLDER, \"dataset_numeric\", \"*.parquet\")).compute().to_pandas()\n",
    "X = dataset.drop(['Target', 'user_id', 'item_id', 'postal_code', 'recency', 'frequency', 'amount',\n",
    "       '2nd_popular_product_type', 'popular_department_no',\n",
    "       '2nd_popular_department_no', 'popular_section_no',\n",
    "       '2nd_popular_section_no', 'last_product_code', '2nd_last_product_code',\n",
    "       'last_product_type', '2nd_last_product_type', 'product_code',\n",
    "       'prod_name', 'department_no', 'detail_desc', 'count_30d_purchased',\n",
    "       'count_7d_purchased', 'Time_Weighted_Purchased'], axis=1)\n",
    "y = dataset['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70c05951-c98f-4176-8968-4d6290ecd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fbbdf60-9fe2-4e28-8156-f474828b29f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c3214-1662-47c4-a23a-5f9f20a948b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5b866f85-0af1-4e30-872c-733e9d8d75b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Selected features: Index(['age', 'popular_product_type', 'product_type_no', 'colour_group_code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Utiliser un modèle de RandomForest pour l'exemple, mais vous pouvez utiliser un autre modèle\n",
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialiser RFE avec le modèle et le nombre de caractéristiques souhaitées\n",
    "# Vous pouvez ajuster le nombre de caractéristiques à sélectionner\n",
    "rfe = RFE(estimator=model, n_features_to_select=4, verbose=1, step=1)\n",
    "\n",
    "# Ajuster RFE sur les données d'entraînement\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir les caractéristiques sélectionnées\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "41f191f3-524f-4007-afa4-31b187c929d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with selected features: 0.7357600120688841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81    437957\n",
      "           1       0.61      0.56      0.58    218276\n",
      "\n",
      "    accuracy                           0.74    656233\n",
      "   macro avg       0.70      0.69      0.69    656233\n",
      "weighted avg       0.73      0.74      0.73    656233\n",
      "\n",
      "0.6906661219827275\n"
     ]
    }
   ],
   "source": [
    "# Créer un nouveau modèle avec les caractéristiques sélectionnées\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "# Calculer la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with selected features:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86cc01a9-ce85-4886-b639-574b0b3ca7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target         1.000000\n",
      "postal_code    0.027657\n",
      "age           -0.096906\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = dataset[['age', 'postal_code', 'Target']].corr()\n",
    "print(correlation_matrix['Target'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3fd7e699-be66-4dd6-8a91-a1cdd0316163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target    1.000000\n",
      "age      -0.096906\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = dataset[['age', 'Target']].corr()\n",
    "print(correlation_matrix['Target'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2bfb4-d1a7-48af-ad9e-f06f0030840d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
